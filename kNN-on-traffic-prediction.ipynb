{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Introduction \n",
    "This is my project in a data mining course. It is to predict bike flows with K-nearest neighbors (kNN).\n",
    "\n",
    "Hubway, is a bike sharing system (BSS) available in Boston. A common problem faced by a sharing system is unbalanced supply and demand. We aim to predict on flow of incoming bikes as well as outgoing bikes given a particular station, date and time frame.\n",
    "\n",
    "To approach this problem, we decided to find similar days of a given date. From there, we predict the proportion of bikes goint from/to the given station. Since we have information on capacity of a station, we can get the number of bikes. \n",
    "\n",
    "1. [Explore the Datasets](kNN-on-traffic-prediction.ipynb#1.-Explore-the-Datasets)\n",
    "2. [What is kNN](kNN-on-traffic-prediction.ipynb#2.-What-is-kNN)\n",
    "3. [Distance Function](kNN-on-traffic-prediction.ipynb#3.-Distance-Function)\n",
    "4. [Nearest Neighbors](kNN-on-traffic-prediction.ipynb#4.-Nearest-Neighbors)\n",
    "5. [Estimation](kNN-on-traffic-prediction.ipynb#5.-Estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import operator\n",
    "\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Explore the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three datasets we use:\n",
    "1. bike trip data \n",
    "2. station capacity\n",
    "3. weather data\n",
    "\n",
    "The first two are available from hubwaydatachallenge (http://hubwaydatachallenge.org), and the weather data is scrapped from https://www.wunderground.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bike trip data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trip data recorded trips themselves (date, start station, end station) and the user (age, sex) if they were registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seq_id  hubway_id  status  duration          start_date  strt_statn  \\\n",
      "0       1          8  Closed         9  7/28/2011 10:12:00        23.0   \n",
      "1       2          9  Closed       220  7/28/2011 10:21:00        23.0   \n",
      "2       3         10  Closed        56  7/28/2011 10:33:00        23.0   \n",
      "3       4         11  Closed        64  7/28/2011 10:35:00        23.0   \n",
      "4       5         12  Closed        12  7/28/2011 10:37:00        23.0   \n",
      "\n",
      "             end_date  end_statn bike_nr  subsc_type zip_code  birth_date  \\\n",
      "0  7/28/2011 10:12:00       23.0  B00468  Registered   '97217      1976.0   \n",
      "1  7/28/2011 10:25:00       23.0  B00554  Registered   '02215      1966.0   \n",
      "2  7/28/2011 10:34:00       23.0  B00456  Registered   '02108      1943.0   \n",
      "3  7/28/2011 10:36:00       23.0  B00554  Registered   '02116      1981.0   \n",
      "4  7/28/2011 10:37:00       23.0  B00554  Registered   '97214      1983.0   \n",
      "\n",
      "   gender  \n",
      "0    Male  \n",
      "1    Male  \n",
      "2    Male  \n",
      "3  Female  \n",
      "4  Female  \n"
     ]
    }
   ],
   "source": [
    "############## trips ##############\n",
    "trip_df = pd.read_csv('./data/hubway_trips.csv')\n",
    "\n",
    "print trip_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the range of the trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-07-28 10:12:00\n",
      "2013-11-30 23:39:00\n"
     ]
    }
   ],
   "source": [
    "print pd.to_datetime(trip_df['start_date'], format='%m/%d/%Y %H:%M:%S').min()\n",
    "print pd.to_datetime(trip_df['start_date'], format='%m/%d/%Y %H:%M:%S').max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly more than two-year data we got here. Not much, but good enough.\n",
    "\n",
    "We consider date and time separately.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seq_id  hubway_id  status  duration start_date  strt_statn   end_date  \\\n",
      "0       1          8  Closed         9  7/28/2011        23.0  7/28/2011   \n",
      "1       2          9  Closed       220  7/28/2011        23.0  7/28/2011   \n",
      "2       3         10  Closed        56  7/28/2011        23.0  7/28/2011   \n",
      "3       4         11  Closed        64  7/28/2011        23.0  7/28/2011   \n",
      "4       5         12  Closed        12  7/28/2011        23.0  7/28/2011   \n",
      "\n",
      "   end_statn bike_nr  subsc_type zip_code  birth_date  gender start_time  \\\n",
      "0       23.0  B00468  Registered   '97217      1976.0    Male   10:12:00   \n",
      "1       23.0  B00554  Registered   '02215      1966.0    Male   10:21:00   \n",
      "2       23.0  B00456  Registered   '02108      1943.0    Male   10:33:00   \n",
      "3       23.0  B00554  Registered   '02116      1981.0  Female   10:35:00   \n",
      "4       23.0  B00554  Registered   '97214      1983.0  Female   10:37:00   \n",
      "\n",
      "   end_time  \n",
      "0  10:12:00  \n",
      "1  10:25:00  \n",
      "2  10:34:00  \n",
      "3  10:36:00  \n",
      "4  10:37:00  \n"
     ]
    }
   ],
   "source": [
    "trip_df['start_time'] = trip_df['start_date'].apply(lambda l: l.split(' ')[1])\n",
    "trip_df['start_date'] = trip_df['start_date'].apply(lambda l: l.split(' ')[0])\n",
    "trip_df['end_time'] = trip_df['end_date'].apply(lambda l: l.split(' ')[1])\n",
    "trip_df['end_date'] = trip_df['end_date'].apply(lambda l: l.split(' ')[0])\n",
    "\n",
    "print trip_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## station capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capacity data contains capcity of the stations for each day\n",
    "\n",
    "We'll want to build a function that returns the capacity of an station at any given day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>update</th>\n",
       "      <th>capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-08-22 16:23:33.557-04</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-08-22 16:23:33.557-04</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-08-22 16:23:33.557-04</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2011-08-22 16:23:33.557-04</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>2011-08-22 16:23:33.557-04</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id                      update  capacity\n",
       "0           3  2011-08-22 16:23:33.557-04        17\n",
       "1           5  2011-08-22 16:23:33.557-04        15\n",
       "2           6  2011-08-22 16:23:33.557-04        15\n",
       "3           8  2011-08-22 16:23:33.557-04        15\n",
       "4           9  2011-08-22 16:23:33.557-04        19"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## capacity ##############\n",
    "df = pd.read_csv('./data/stationstatus.csv', usecols=['station_id', 'update','capacity'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       capacity\n",
      "station_id update              \n",
      "3          2011-08-22        17\n",
      "           2011-08-23        17\n",
      "           2011-08-24        17\n",
      "           2011-08-25        17\n",
      "           2011-08-26        16\n"
     ]
    }
   ],
   "source": [
    "df['update'] = df['update'].apply(lambda l: l.split(' ')[0])\n",
    "capacity_df = df.groupby(['station_id', 'update']).max()\n",
    "\n",
    "print capacity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.8414278195\n"
     ]
    }
   ],
   "source": [
    "avg_cap = capacity_df['capacity'].mean()\n",
    "\n",
    "print avg_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cap(stn, date):\n",
    "    if stn in capacity_df.index:        \n",
    "        try:\n",
    "            cap = capacity_df.loc[stn].loc[date]['capacity']\n",
    "        except:\n",
    "            cap = capacity_df.loc[stn].mean()\n",
    "    else:\n",
    "        cap = avg_cap\n",
    "    return cap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the capacity of a station at the given day exists, we find the capacity. Elsewise, estimate the capacity by the average capacity of all stations. \n",
    "\n",
    "Like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "15.8414278195\n"
     ]
    }
   ],
   "source": [
    "print get_cap(33, '2012-09-30')\n",
    "print get_cap(180, '2012-09-30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weather data contains information on minimum, maximum temperature and precipitation for each day in Boston.\n",
    "\n",
    "We further added weekday and season information to the weather data. The preparation of weather data is skipped here. Let's use it as a readily available one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  weekday  season           weather  max_temp  min_temp  \\\n",
      "0  7/28/2011        1  summer  Scattered Clouds        24        20   \n",
      "1  7/29/2011        1  summer              Rain        26        19   \n",
      "2  7/30/2011        0  summer     Partly Cloudy        32        23   \n",
      "3  7/31/2011        0  summer  Scattered Clouds        33        21   \n",
      "4   8/1/2011        1  summer     Partly Cloudy        34        22   \n",
      "\n",
      "  precipitation  \n",
      "0             0  \n",
      "1          3.56  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0  \n"
     ]
    }
   ],
   "source": [
    "############## weather ##############\n",
    "weather = pd.read_csv('./data/weatherBoston.csv')\n",
    "print weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather data requires a bit of cleaning.\n",
    "\n",
    "The precipitation is of mixed types as shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 857 entries, 0 to 856\n",
      "Data columns (total 7 columns):\n",
      "date             857 non-null object\n",
      "weekday          857 non-null int64\n",
      "season           857 non-null object\n",
      "weather          857 non-null object\n",
      "max_temp         857 non-null int64\n",
      "min_temp         857 non-null int64\n",
      "precipitation    857 non-null object\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 46.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print weather.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we firstly convert the precipitation column to numeric one. And then fill the null entries with average precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "2.95878431373\n"
     ]
    }
   ],
   "source": [
    "# precipitation: str to numeric\n",
    "weather.precipitation = weather.precipitation.apply(pd.to_numeric, errors='coerce')\n",
    "print weather.precipitation.isnull().sum()\n",
    "avg = weather.precipitation.mean()\n",
    "print avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# precipitation: fill up the null value with average precipitation\n",
    "weather.precipitation = weather.precipitation.fillna(avg)\n",
    "print weather.precipitation.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. What is kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind kNN algorithm is to predict unknown values based on the most similar known values.\n",
    "\n",
    "Taking computer purchase as an example, a computer's performance is largely determined by its configurations. If you know there is a good product, you are likely to look for similar configurations in order to to get a good one. \n",
    "\n",
    "kNN is as straightforward as that. \n",
    "\n",
    "In our problem, to predict bike flow between stations, we introduced weather as attributes for trips. Think in this way, a trip decision (i.e. to rent and ride a bike), is largely dependent on the traffic condition (i.e. peak hour or not) and the day condition (i.e rainy or sunny).\n",
    "\n",
    "It draws down to find similar values -- we can use weather to find similar days, and subset on trips dataset accordingly to find similar trips.  \n",
    "\n",
    "Again, it is back to the idea of predicting unknown values based on the most similar known values.\n",
    "\n",
    "To understand and impolement kNN, the algorithm breaks down to:\n",
    "1. Distance -- How to define similar days?\n",
    "2. Nearest Neighbors -- How to subset trips on neighboring days based on distance in 1\n",
    "3. Estimation -- How to predict unknown using known values in 2\n",
    "\n",
    "Let's walk through it one by one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Distance Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's setup our input values first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########### parameters ##############\n",
    "# creates a day and a timeframe\n",
    "dateInput = '9/4/2012'\n",
    "timeFrameStart = \"10:00:00\"\n",
    "timeFrameEnd = \"12:00:00\"\n",
    "# tell which station you are interested in\n",
    "stn = 33\n",
    "# 20 is the number of nearest neighbor we consider\n",
    "k = 20\n",
    "# this is the average capacity of a staion calculated earlier\n",
    "avgCapa = 15.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The we need a list of candidates. Here we extract list of days from the trip data. Basically this is the scope of estimation. We don't want to have days outside of the known trips, because that will not bring any known information to help the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## creates a list with all the days (used for the KNN algo)\n",
    "mask = (trip_df['start_time'] >= timeFrameStart) \\\n",
    "     & (trip_df['end_time'] <= timeFrameEnd) \\\n",
    "     & (trip_df['strt_statn'] == stn) \\\n",
    "     & (trip_df['start_date'] == trip_df['start_date']) \\\n",
    "     & (trip_df['start_date'] != dateInput)\n",
    "\n",
    "day_list = list(weather['date'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's find K nearest neighbors to a day in the list of all the days\n",
    "\n",
    "What makes a day similar? We want to define our distance between two days as the following:\n",
    "1. the distance is close to infinity if they are not both weekdays or weekend;\n",
    "2. the closer the days are in time, the smaller the distance is;\n",
    "3. the closer the minimum and maximum temperatures are, the smaller the distance is;\n",
    "4. a difference of 4 degrees has the same impact on the distance as a one year difference.\n",
    "\n",
    "Elsewise, you can consider Euclidean distance, which is simply a sum of squared distances of each attribute. Here we construct our distance function to suit our problem. Nevertheless, the key is to come up with a distance measurement so as to quantify similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kNN(date, k):\n",
    "    # initiation\n",
    "    dist_list = []\n",
    "    neighbors = []\n",
    "    date_weather = weather[weather['date'] == date]\n",
    "\n",
    "    # distance specifications\n",
    "    weekday_dist = 50000\n",
    "    season_dist = 1000\n",
    "    day_dist = 100\n",
    "    \n",
    "    for day in day_list:\n",
    "        if day != date:\n",
    "            distance = 0\n",
    "            compare_weather = weather[weather['date'] == day]   \n",
    "            if int(date_weather['weekday'].iloc[0]) != int(compare_weather['weekday'].iloc[0]):\n",
    "                distance += weekday_dist\n",
    "            if date_weather['season'].iloc[0] != compare_weather['season'].iloc[0]:\n",
    "                distance += season_dist\n",
    "            timeDif = (dt.datetime.strptime(date, '%m/%d/%Y') - dt.datetime.strptime(day, '%m/%d/%Y')).days / float(day_dist)\n",
    "            max_temp_Dif = date_weather['max_temp'].iloc[0] - compare_weather['max_temp'].iloc[0]\n",
    "            min_temp_Dif = date_weather['min_temp'].iloc[0] - compare_weather['min_temp'].iloc[0]\n",
    "            prec_Dif = date_weather['precipitation'].iloc[0] - compare_weather['precipitation'].iloc[0]\n",
    "\n",
    "            distance += timeDif * timeDif\n",
    "            distance += max_temp_Dif * max_temp_Dif * 2\n",
    "            distance += min_temp_Dif * min_temp_Dif * 2\n",
    "            distance += prec_Dif * prec_Dif\n",
    "\n",
    "            dist_list.append((day, distance))\n",
    "\n",
    "    dist_list.sort(key=operator.itemgetter(1))\n",
    "    for i in range(k):\n",
    "        neighbors.append((dist_list[i][0]))\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gives us the k-nearest days of the given day.\n",
    "\n",
    "The neighboring days are pretty much cyclical. This is understandable. Days consecutive are most likely to be similar, and days around the same season in different years can be similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7/31/2012', '9/13/2013', '6/28/2013', '9/6/2011', '9/19/2012', '7/29/2013', '7/25/2013', '9/7/2012', '6/27/2012', '8/22/2011', '9/2/2013', '7/9/2013', '8/13/2013', '9/5/2012', '8/8/2011', '8/10/2011', '6/26/2012', '9/18/2012', '9/7/2011', '7/29/2011']\n"
     ]
    }
   ],
   "source": [
    "kNN_days = kNN(dateInput, k)\n",
    "print kNN_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have got a list of similar days. \n",
    "\n",
    "We can use similar days to subset the trip data to get similar trips. \n",
    "\n",
    "And that would be the nearest neighbors of a trip that we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        seq_id  hubway_id  status  duration start_date  strt_statn   end_date  \\\n",
      "12204    12205      13402  Closed       619  8/10/2011        33.0  8/10/2011   \n",
      "12205    12206      13403  Closed      1239  8/10/2011        33.0  8/10/2011   \n",
      "28369    28370      31587  Closed     20670  8/22/2011        33.0  8/23/2011   \n",
      "45661    45662      52504  Closed       152   9/6/2011        33.0   9/6/2011   \n",
      "299320  299321     340929  Closed       375  6/26/2012        33.0  6/26/2012   \n",
      "\n",
      "        end_statn bike_nr  subsc_type zip_code  birth_date  gender start_time  \\\n",
      "12204        14.0  B00293  Registered   '02134      1978.0    Male   10:27:00   \n",
      "12205        23.0  B00286  Registered   '02215      1965.0  Female   10:28:00   \n",
      "28369        53.0  B00300      Casual      NaN         NaN     NaN   20:27:00   \n",
      "45661        10.0  B00188  Registered   '01462      1981.0    Male   11:41:00   \n",
      "299320        9.0  B00605  Registered   '02215      1981.0    Male   10:07:00   \n",
      "\n",
      "        end_time  \n",
      "12204   10:37:00  \n",
      "12205   10:48:00  \n",
      "28369   02:12:00  \n",
      "45661   11:43:00  \n",
      "299320  10:13:00  \n"
     ]
    }
   ],
   "source": [
    "# find the trips that comes from the station, at similar days, similar times\n",
    "# filter out the give dateInput as you don't want to predict on the same data\n",
    "mask = (trip_df['start_date'].isin(kNN_days)) \\\n",
    "     & (trip_df['start_time'] >= timeFrameStart) \\\n",
    "     & (trip_df['end_time'] <= timeFrameEnd) \\\n",
    "     & (trip_df['strt_statn'] == stn) \\\n",
    "     & (trip_df['start_date'] == trip_df['start_date']) \\\n",
    "     & (trip_df['start_date'] != dateInput)\n",
    "\n",
    "to_trips = trip_df[mask]\n",
    "print to_trips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two common methods to deal with kNN predictions are regression and averaging. \n",
    "\n",
    "Among the two, I personally prefer averaging. Especially you can come up with your rules on combining the results such as:\n",
    "* Majority vote\n",
    "* Distance weighted vote\n",
    "\n",
    "In our project, we finally used regression as time is progressive.\n",
    "\n",
    "No matter what method is used, the idea is still to rely on the predictions of the k examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a regression of proportion of outgoing bikes on time. \n",
    "\n",
    "First we fit the list of similar days to numerical ones. This is our x variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 10, 12, 24, 39, 40, 333, 334, 368, 404, 406, 417, 418, 700, 711, 727, 731, 746, 766, 777]\n"
     ]
    }
   ],
   "source": [
    "kNN_dates = []\n",
    "for ele in kNN_days:\n",
    "    kNN_dates.append(dt.datetime.strptime(ele, '%m/%d/%Y'))\n",
    "kNN_dates = np.sort(kNN_dates)\n",
    "\n",
    "timeArray = [0]\n",
    "for i in range(1, len(kNN_dates)):\n",
    "    timeArray.append(timeArray[i-1] + (kNN_dates[i] - kNN_dates[i-1]).days)\n",
    "print timeArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then construct the corresponding dependent variable which is a list of proportion of outgoing bikes by day. \n",
    "\n",
    "The proportion is the total trips made divided by the capacity of the station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            hubway_id\n",
      "start_date           \n",
      "6/26/2012           4\n",
      "6/27/2012           4\n",
      "6/28/2013           3\n",
      "7/25/2013           4\n",
      "7/29/2013           4\n"
     ]
    }
   ],
   "source": [
    "## calculate the number of trip comes from the station per day\n",
    "tripPerDay = to_trips[['start_date', 'hubway_id']].groupby('start_date').count()\n",
    "print tripPerDay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17130846032580138, 0.45682256086880368, 0.17130846032580138, 0.057102820108600461, 0.57102820108600461, 0.22841128043440184, 0.22841128043440184, 0.68523384130320553, 0.22841128043440184, 0.057102820108600461, 0.74233666141180599, 0.62813102119460507, 0.2855141005430023, 0.17130846032580138, 0, 0.11420564021720092, 0.22841128043440184, 0.39971974076020322, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# get the corresponding number of trip array\n",
    "# tripArray: number of trips divided by the capacity of the station at that day \n",
    "tripArray = []\n",
    "for day in kNN_days:\n",
    "    try:\n",
    "        num_trips = tripPerDay.loc[day]['hubway_id']\n",
    "        cap = get_cap(stn, day)\n",
    "        tripArray.append(num_trips / float(cap))\n",
    "    except:\n",
    "        tripArray.append(0)\n",
    "\n",
    "print tripArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have x and y variables. Let's write a linear regression function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## do a regression on that\n",
    "## does the linear regression of the Yarray(timeArray) and display the result if plot\n",
    "def linearRegression(XArray, YArray, plot):\n",
    "    coef = np.polyfit(XArray, YArray, 1)\n",
    "    p = np.poly1d(coef)\n",
    "    # err\n",
    "    err = 0\n",
    "    estim = []\n",
    "    for i in range(len(XArray)):\n",
    "        estim.append(p(XArray[i]))\n",
    "        err += (estim[i] - YArray[i]) * (estim[i] - YArray[i])\n",
    "    \n",
    "    if plot:\n",
    "        #_ = plt.plot(time, trips, '.', xp, p(xp), '-')\n",
    "        plt.plot(XArray, YArray, 'ro', XArray, p(XArray), '--k')\n",
    "        \n",
    "        plt.ylim(-1, 1)\n",
    "        plt.show()\n",
    "    \n",
    "    return coef, err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result and visualization of the regression output is as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEACAYAAAC+gnFaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10baa69d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef, err = linearRegression(timeArray, tripArray, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -2.13723720e-04   3.56332495e-01] 0.959659487748\n"
     ]
    }
   ],
   "source": [
    "print coef, err "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now predict with the fitted line. \n",
    "\n",
    "Get the timestamp of the studied day in the same space as our time array, and estimate the proportion of outgoing bikes of the studied day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n"
     ]
    }
   ],
   "source": [
    "newDay = (dt.datetime.strptime(dateInput, '%m/%d/%Y') - kNN_dates[0]).days\n",
    "print newDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.270201835473\n"
     ]
    }
   ],
   "source": [
    "# estimation\n",
    "p = np.poly1d(coef)\n",
    "print p(newDay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiply the proportion with the station's capacity. This is the estimation of outgoing bikes for the studied station and time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "print np.floor(p(newDay) * get_cap(stn, dateInput)['capacity'] + 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the actual number of trips?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "mask = (trip_df['strt_statn']==stn) \\\n",
    "     &(trip_df['start_date']==dateInput) \\\n",
    "     & (trip_df['start_time'] >= timeFrameStart) \\\n",
    "     & (trip_df['end_time'] <= timeFrameEnd)\n",
    "print trip_df[mask].end_statn.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Averaging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averaging is simply find the average proportion of outgoing bikes for the list of similar days. \n",
    "\n",
    "Our project used regression. So here I just put a line for demonstration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "print np.floor(np.mean(tripArray) * get_cap(stn, dateInput)['capacity'] + 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# What Happened After\n",
    "1. The incoming flow of bikes to a station is also estimated. It uses the same method so is skipped in this notebook\n",
    "2. The value of k has to be adjusted (crossvalidation)\n",
    "    * can overfit (k too low) \n",
    "    * can underfit (k too high)\n",
    "    * in the school project, we did come to the conclusion of k=10 as the optimal through crossvalidation\n",
    "3. Several evaluations are constructed\n",
    "    * measure 1: the percentage of correct predictions for all the stations;\n",
    "    * measure 2: 1 minus the mean absolute percentage error (MAPE) for stations with non-zero predicted bike flow\n",
    "    * measure 3: the ratio of the total predicted flow over actual flow in the system, stratified by positive flow and negative flow.\n",
    "    * The above 1 to 1 comparison on prediction and actual results are merely an illustration.\n",
    "\n",
    "And finally, we did get a good grade in this course. Hurray!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
